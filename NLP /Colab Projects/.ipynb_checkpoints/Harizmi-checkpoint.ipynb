{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJZOjbweTslS",
    "outputId": "78a805d5-f486-4895-a953-259e685fa924"
   },
   "outputs": [],
   "source": [
    "! pip install html2text\n",
    "! pip install transformers==4.3.3\n",
    "! pip install -U imbalanced-learn\n",
    "! pip install wandb\n",
    "! git clone https://github.com/NVIDIA/apex\n",
    "! cd apex\n",
    "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /kaggle/working/apex/\n",
    "! pip install simpletransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGVapjuyCuXx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrB6myMOAnS0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beY-j_JQA1kI"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzOBPFUOTzsI"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "from html2text import html2text\n",
    "import re\n",
    "import warnings\n",
    "import itertools\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import chardet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRnUrG-_TUwv"
   },
   "outputs": [],
   "source": [
    "encoding = \"utf-8\"\n",
    "sep = \";\"\n",
    "\n",
    "\n",
    "migros_path = \"/content/drive/MyDrive/Data/A_Data/\"\n",
    "\n",
    "migros_raw_product_1 = pd.read_csv(fr\"{migros_path}products1Yeni.csv\",\n",
    "                                   sep=sep, encoding=encoding)\n",
    "migros_raw_product_2 = pd.read_csv(fr\"{migros_path}products2Yeni.csv\",\n",
    "                                   sep=sep, encoding=encoding)\n",
    "migros_raw_product_3 = pd.read_csv(fr\"{migros_path}products3Yeni.csv\",\n",
    "                                   sep=sep, encoding=encoding)\n",
    "migros_raw_product_4 = pd.read_csv(fr\"{migros_path}products4Yeni.csv\",\n",
    "                                   sep=sep, encoding=encoding)\n",
    "\n",
    "__frames = [migros_raw_product_1, migros_raw_product_2,\n",
    "            migros_raw_product_3, migros_raw_product_4]\n",
    "df = shuffle(pd.concat(__frames))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkpUCY1RTdf_"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "__WPT = nltk.WordPunctTokenizer()\n",
    "__stop_words_list = nltk.corpus.stopwords.words('turkish')\n",
    "__stop_words_list += [\"g\", \"kg\", \"ml\", \"l\", \"cm\",\n",
    "                      \"x\", \"li\", \"lı\", \"ay\", \"lü\", \"lu\",\n",
    "                      \"ad\", \"adet\", \"gr\", \"boy\", \"orta\", \"küçük\", \"büyük\",\n",
    "                      \"paket\", \"adetx\", \"köy\", \"doğal\"]\n",
    "\n",
    "__TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "\n",
    "def html_totext(text):\n",
    "    return html2text(text)\n",
    "\n",
    "\n",
    "def remove_tags(text):\n",
    "    return __TAG_RE.sub(' ', text)\n",
    "\n",
    "\n",
    "def remove_undefine_words(text):\n",
    "    text = text.replace('&;nbsp;', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('8&;#39', \"'\")\n",
    "    text = text.replace('&lt', '')\n",
    "    text = text.replace('p&gt;', '')\n",
    "    text = text.replace('strong&gt;', ' ')\n",
    "    text = text.replace('&;amp;', '&')\n",
    "    text = text.replace('&;#39;', r'\\ ')\n",
    "    text = text.replace('&;', '')\n",
    "    text = text.replace('nbsp;', ' ')\n",
    "    text = text.replace('//', ' ')\n",
    "    text = text.replace(' /', ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    txt = remove_undefine_words(text)\n",
    "    txt = html_totext(text)\n",
    "    txt = remove_tags(txt)\n",
    "    return txt.strip()\n",
    "\n",
    "\n",
    "def lower_letters(txt):\n",
    "    txt = txt.replace(\"İ\", \"i\")\n",
    "    return txt.lower()\n",
    "\n",
    "\n",
    "def resub_comma(txt):\n",
    "    return txt.replace(\",\", \" \")\n",
    "\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    return ' '.join([word for word in txt.split()\n",
    "                     if word.strip() not in __stop_words_list \n",
    "                     and len(word) > 1]) \n",
    "\n",
    "\n",
    "def remove_punctuation(txt):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', txt)\n",
    "\n",
    "\n",
    "def remove_repeatedLetter(txt):\n",
    "     return (''.join(i for i, _ in itertools.groupby(txt)))\n",
    " \n",
    "\n",
    "def remove_integer(txt):\n",
    "    return ''.join([word for word in txt if not word.isdigit()])\n",
    "\n",
    "\n",
    "def just_one_word(txt):\n",
    "    new_txt = []\n",
    "    for word in txt.split(' '):\n",
    "        if word not in new_txt:\n",
    "            new_txt.append(word)\n",
    "    return ' '.join(new_txt)\n",
    "\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = html_totext(txt)\n",
    "    txt = remove_undefine_words(txt)\n",
    "    txt = remove_tags(txt)\n",
    "    txt = lower_letters(txt)\n",
    "    txt = resub_comma(txt)\n",
    "    txt = remove_punctuation(txt)\n",
    "    txt = remove_integer(txt)\n",
    "    txt = remove_repeatedLetter(txt)\n",
    "    txt = just_one_word(txt)\n",
    "    txt = remove_stopwords(txt)\n",
    "    return txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wAcuFrTWC_H"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['uMarka'])\n",
    "df = df.dropna(subset=['urunAdi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnqLs7CuWeaG"
   },
   "outputs": [],
   "source": [
    "del df['Unnamed: 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQzVVrFOWlTH"
   },
   "outputs": [],
   "source": [
    "df.drop(df[df[\"urunKategorileri\"]=='Oreal'].index, inplace = True) \n",
    "df.drop(df[df[\"urunKategorileri\"]=='Guy'].index, inplace = True) \n",
    "df.drop(df[df[\"urunKategorileri\"]=='Shoulders'].index, inplace = True) \n",
    "df.drop(df[df[\"urunKategorileri\"]=='Bugün Eklenenler'].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYbK0GfnWobn"
   },
   "outputs": [],
   "source": [
    "df[\"uMarka\"] = df[\"uMarka\"].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gscQ_1hGWrH2"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwgDh-iYWt7R"
   },
   "outputs": [],
   "source": [
    "def get_last_category(df2):\n",
    "    category = \"\" \n",
    "    for i in range(7, 0, -1):\n",
    "        if str(df2[i]) != \"nan\" :\n",
    "            category = df2[i]\n",
    "            break\n",
    "    return str(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw9lrk4kWuAo"
   },
   "outputs": [],
   "source": [
    "df[\"new_kat\"] = df.apply(get_last_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A60GfXP9W43X"
   },
   "outputs": [],
   "source": [
    "df[\"urunAdi\"] = df[\"urunAdi\"].apply(clean_text)\n",
    "train_df = df[[\"urunKategorileri\",\"urunAdi\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRqWm97OUDh0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCQ-5wI46YIr"
   },
   "outputs": [],
   "source": [
    "train_df=train_df.rename(columns={'new_kat':'cat',\n",
    "                          'urunAdi':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4sKcEjr6axF"
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSRgnkAQ6hgq"
   },
   "outputs": [],
   "source": [
    "print(train_df.cat.unique())\n",
    "cat_size = len(train_df.cat.unique())\n",
    "print(\"Total categories\",cat_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYBnJXGy6hlK"
   },
   "outputs": [],
   "source": [
    "train_df['labels'] = pd.factorize(train_df.cat)[0]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xP6kMwv96hn0"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_df, test_size=0.0001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNEsfvH46hqM"
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12MM1boK7tR8"
   },
   "outputs": [],
   "source": [
    "model = ClassificationModel('bert', 'bert-base-multilingual-uncased', num_labels=cat_size, \n",
    "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True,\n",
    "                                  'num_train_epochs': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diTy6fVd7v2e"
   },
   "outputs": [],
   "source": [
    "model.train_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tL_gO4gEOkz"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"/content/drive/MyDrive/testData.csv\",encoding=\"utf-8\")\n",
    "\n",
    "_category = train_df.cat.unique().tolist()\n",
    "def test_ml(txt):\n",
    "    raw_txt = txt\n",
    "    txt = clean_text(txt)\n",
    "    predictions, raw_outputs  = model.predict([txt])\n",
    "    return str(_category[predictions[0]])\n",
    "     \n",
    "test_data[\"new_cat\"] = test_data[\"name\"].apply(test_ml)\n",
    "test_data.to_csv(r\"/content/drive/Mydrive/sonuc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qr5LRYdRFHHe"
   },
   "outputs": [],
   "source": [
    "handle = open(r\"/content/drive/MyDrive/new_ML.dat\", \"wb\")pickle.dump(model, handle)\n",
    "handle.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "new2_marketlb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
